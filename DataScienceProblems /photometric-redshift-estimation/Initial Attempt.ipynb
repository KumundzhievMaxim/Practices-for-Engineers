{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class BasePipeLine:\n",
    "    def __init__(self, train, test, sample):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.sample = sample\n",
    "        self.KNNR = KNeighborsRegressor()\n",
    "        self.DTR = DecisionTreeRegressor()\n",
    "        self.SVR = SVR()\n",
    "        self.SGDR = SGDRegressor()\n",
    "        #self.algorithms = [self.KNNR, self.DTR, self.SVR, self.SGDR]\n",
    "        self.algorithms = [self.SVR]\n",
    "        self.params_dict = {\n",
    "            #'KNeighborsRegressor': {'n_neighbors':list(range(3, 11))},\n",
    "            'SVR' : {'kernel': ['rbf'], 'C':[1.5], 'gamma':[1e-4],'epsilon':[0.1]},\n",
    "            #'DecisionTreeRegressor' : {\"min_samples_split\": [10, 20], \"max_depth\": [2, 6]},\n",
    "            #'SGDRegressor': {'alpha': 10.0 ** -np.arange(1, 3), 'penalty': ['l2'], 'learning_rate': ['optimal']}\n",
    "        }\n",
    "                \n",
    "    def data_transform(self):\n",
    "        X = self.train.drop(['redshift'], axis=1)\n",
    "        y = self.train['redshift']\n",
    "        X_test = self.test.drop(['ID'], axis=1)\n",
    "        y_test = self.sample.drop(['ID'], axis=1).values\n",
    "        return X, y, X_test, y_test\n",
    "    \n",
    "    \n",
    "    def grid_search_cv(self, X_train, X_test, y_train, y_test):\n",
    "        results = [] \n",
    "        for algorithm in self.algorithms:\n",
    "            clf = GridSearchCV(estimator=algorithm, param_grid=self.params_dict['{}'.format(algorithm.__class__.__name__)], cv=2, scoring='neg_mean_squared_error', n_jobs=-1, verbose=True).fit(X_train, y_train)\n",
    "            \n",
    "            best_model = clf.best_estimator_\n",
    "            \n",
    "            predictions = clf.best_estimator_.predict(X_test)\n",
    "            results.append(mean_squared_error(y_test, predictions))\n",
    "            \n",
    "            submission_df = pd.DataFrame(columns=['ID', 'redshift'])\n",
    "            submission_df['redshift'] = predictions\n",
    "            submission_df['ID'] = submission_df['redshift'].index\n",
    "            submission_df.to_csv('submission_{}.csv'.format(algorithm.__class__.__name__), index = False)\n",
    "        return [best_model, results]\n",
    "    \n",
    "    def cat_boost(self, X_train, X_test, y_train, y_test):\n",
    "        import CatBoostRegressor\n",
    "        cat = CatBoostRegressor(logging_level='Silent', random_state=45, early_stopping_rounds=300)\n",
    "        predictions = cat.fit(X_train, y_train).predict(X_test)\n",
    "        score = mean_squared_error(y_test, predictions)\n",
    "        return score\n",
    "                        \n",
    "\n",
    "    def run(self):\n",
    "        X, y, X_test, y_test = BasePipeLine(train, test, sample).data_transform()\n",
    "        logging.info('Transformation finished')\n",
    "        \n",
    "        best_model, results = self.grid_search_cv(X, X_test, y, y_test)\n",
    "        logging.info('Fitting models finished')\n",
    "        logging.info('Evaluating Finished')\n",
    "        return best_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('testX.csv')\n",
    "sample = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVR(C=1.5, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0001,\n",
       "     kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       " [0.0013409650420027374])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasePipeLine(train, test, sample).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
