{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow - Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWoKervshKI8",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to TensorFlow\n",
        "In this notebook we will go through the basics in TensorFlow, build a simple multilayer perceptron and try out the TensorBoard visualization utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpslynzlh9Cg",
        "colab_type": "text"
      },
      "source": [
        "## Low-level API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYP0GTRTl1fd",
        "colab_type": "text"
      },
      "source": [
        "### Basics\n",
        "Here we will see how to write a simple Hello, World! application in TensorFlow and  learn about the basics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7UCfGhAl3JW",
        "colab_type": "text"
      },
      "source": [
        "#### Hello, World!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sDc11D4imrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q6TTh14jd4O",
        "colab_type": "text"
      },
      "source": [
        "After importing the module, we can create a Constant operation, which will contain the given value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwBofK3CitK3",
        "colab_type": "code",
        "outputId": "c26fab1d-5e71-441c-b2a6-fb87da342471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "hello = tf.constant('Hello, World!')\n",
        "print(hello)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7i_ZRykYAY",
        "colab_type": "text"
      },
      "source": [
        "By printing it we can notice that it won't output its value. The variable `hello` just refers to an operation that we have to evaluate to get its value. To do so we have to create a Session then run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArerW0ixi49h",
        "colab_type": "code",
        "outputId": "37a00827-8db9-4990-f91e-c854e7b63413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "print(sess.run(hello))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello, World!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTuamkoclfuQ",
        "colab_type": "text"
      },
      "source": [
        "#### Tensors\n",
        "As we saw, we can't directly ask for the value of a constants. This is because behind the screens by defining them we are building a **[computational graph](https://www.tensorflow.org/api_docs/python/tf/Graph)**. A computational graph consists of\n",
        "* **[Operations](https://www.tensorflow.org/api_docs/python/tf/Operation)**, which are the nodes of the graph, and\n",
        "* **[Tensors](https://www.tensorflow.org/api_docs/python/tf/Tensor)**, which are the edges.  These represent the values that will flow through the graph.\n",
        "\n",
        "A **Tensor** consists of a set of a set of primitive  values shaped into an array. Its **rank** shows the number of dimensions it have, while its **shape** specifies the array's length along each dimension. When evaluated, Tensors are pretty similar to numpy's ndarrays.\n",
        "\n",
        "\n",
        "Let's see some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04eFNXCGrSwE",
        "colab_type": "code",
        "outputId": "d8cb248d-6be3-463d-f4a8-936877c8f71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# rank 0 tensors with shape ()\n",
        "a = tf.constant(3.14)\n",
        "b = tf.constant(42, dtype=tf.float32)\n",
        "c = tf.constant(1)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "# rank 1 tensor with shape (3,) and (6)\n",
        "vec1 = tf.constant([1, 2, 3])\n",
        "vec2 = tf.constant(np.arange(6), dtype=tf.float32)\n",
        "print(vec1)\n",
        "print(vec2)\n",
        "\n",
        "# rank 2 tensor with shape (3, 1) and (1, 3)\n",
        "mtx1 = tf.constant([[1.], [3.], [2.]])\n",
        "mtx2 = tf.constant(np.ones(shape=(1,3), dtype=np.float32))\n",
        "print(mtx1)\n",
        "print(mtx2)\n",
        "\n",
        "# Placeholders are special Tensors.\n",
        "# Unlike constants, they receive their value in sess.run().\n",
        "# At this point they are just empty stubs.\n",
        "x = tf.placeholder(tf.int32)\n",
        "y = tf.placeholder(tf.int32)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_8:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_9:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_10:0\", shape=(), dtype=int32)\n",
            "Tensor(\"Const_11:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Const_12:0\", shape=(6,), dtype=float32)\n",
            "Tensor(\"Const_13:0\", shape=(3, 1), dtype=float32)\n",
            "Tensor(\"Const_14:0\", shape=(1, 3), dtype=float32)\n",
            "Tensor(\"Placeholder:0\", dtype=int32)\n",
            "Tensor(\"Placeholder_1:0\", dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6z-7wmwwTlZ",
        "colab_type": "text"
      },
      "source": [
        "#### Basic Operations\n",
        "\n",
        "After defining some tensors, you can do operations with them: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-XR_QdB_8Ad",
        "colab_type": "code",
        "outputId": "c7ec9466-9f81-438d-9ae5-09fa7a3516ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "a_plus_b = a + b\n",
        "a_plus_2b = tf.add(a, 2*b)\n",
        "print(a * b)\n",
        "print(a / b)\n",
        "mtx1_mtx2 = tf.matmul(mtx1, mtx2)\n",
        "mtx2_mtx1 = tf.matmul(mtx2, mtx1)\n",
        "x_plus_y = tf.add(x, y)\n",
        "x_y = tf.multiply(x, y)\n",
        "\n",
        "print(x_plus_y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"mul_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"truediv_2:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Add_7:0\", dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-TztWnu-s-K",
        "colab_type": "text"
      },
      "source": [
        "As you can see they are not evaluated yet. Some of them could not even be, even if we wanted! `x_plus_y` is the sum of `x` and `y` but both are just placeholders, they don't have any value yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkmnXCGj2NWO",
        "colab_type": "text"
      },
      "source": [
        "#### Session\n",
        "\n",
        "To evaluate tensors, instantiate a **[tf.Session](https://www.tensorflow.org/api_docs/python/tf/Session)** object, informally known as a **session**. A session encapsulates the state of the TensorFlow runtime, and runs TensorFlow operations. The `run` function returns the value of the evaluated Tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Uer__YH0GZ",
        "colab_type": "code",
        "outputId": "f1a28298-0b97-433d-ac63-657bd4b120b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  print(\"a + b:\", sess.run(a_plus_b))\n",
        "  print(\"a + 2*b:\", sess.run(a_plus_2b))\n",
        "  print(\"mtx1 * mtx2:\", sess.run(mtx1_mtx2))\n",
        "  print(\"mtx2 * mtx1:\", sess.run(mtx2_mtx1))\n",
        "  \n",
        "  # When using placeholders, pass their value in the feed_dict parameter\n",
        "  print(\"x + y:\", sess.run(x_plus_y, feed_dict={x: 3, y: 5}))\n",
        "  print(\"x * y:\", sess.run(x_y, feed_dict={x: 3, y: 5}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a + b: 45.14\n",
            "a + 2*b: 87.14\n",
            "mtx1 * mtx2: [[1. 1. 1.]\n",
            " [3. 3. 3.]\n",
            " [2. 2. 2.]]\n",
            "mtx2 * mtx1: [[6.]]\n",
            "x + y: 8\n",
            "x * y: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Y94Jwi3X5X",
        "colab_type": "text"
      },
      "source": [
        "### Building  a Multilayer Perceptron\n",
        "\n",
        "Here will see how to build a simple neuronal network with TensorFlow using only the low-level API.\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)  \n",
        "\n",
        "It will classify handwritten digits from MNIST. The network will have two dense layers and a final softmax layer with 10 outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRAnuodw3sSS",
        "colab_type": "code",
        "outputId": "c5aa2e39-8eaa-4d06-c841-2937d0a9cb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# First load the MNIST dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-c3d55fec490c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqx8Cd0GJCjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "num_steps = 500\n",
        "batch_size = 32\n",
        "display_step = 50\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of neurons\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons\n",
        "n_input = 784 # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "# tf Graph input and target tensors\n",
        "X = tf.placeholder(tf.float32, [None, n_input], name='InputData')\n",
        "Y = tf.placeholder(tf.float32, [None, n_classes], name='LabelData')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgbAy7YJJG3o",
        "colab_type": "code",
        "outputId": "29b8bb74-50e7-4522-a2bb-cff986ed9313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "  'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='W1'),\n",
        "  'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='W2'),\n",
        "  'w3': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='W3')\n",
        "}\n",
        "biases = {\n",
        "  'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='b1'),\n",
        "  'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='b2'),\n",
        "  'b3': tf.Variable(tf.random_normal([n_classes]), name='b3')\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqbxNdULJJLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "def neural_net(x):\n",
        "  # A fully connected layer with 256 neurons.\n",
        "  # Remember, a fully connected layer's formula is\n",
        "  #     o = g(x*W+b)\n",
        "  # where g is the activation function, W is weight matrix and b is the bias vector.\n",
        "  \n",
        "  layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  \n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  \n",
        "  out_layer = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BC7IYQuJMKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encapsulating all ops into scopes, making Tensorboard's Graph\n",
        "# Visualization more convenient (see next section about Tensorboard).\n",
        "with tf.name_scope('Model'):\n",
        "  # Build model\n",
        "  logits = neural_net(X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "with tf.name_scope('Loss'):\n",
        "  # Softmax Cross entropy (cost function)\n",
        "  # This is the cross entropy loss and softmax activation fused into one operation\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
        "                                                                labels=Y))\n",
        "# The training operations\n",
        "with tf.name_scope('Adam'):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "  train_op = optimizer.minimize(loss)\n",
        "  \n",
        "# Create operations to calculate the accuracy\n",
        "with tf.name_scope('Accuracy'):\n",
        "  correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyNj75gjJRFB",
        "colab_type": "code",
        "outputId": "1dca495c-a748-4f4a-a378-7da3879a65cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            l, acc = sess.run([loss, accuracy], \n",
        "                              feed_dict={X: batch_x, Y: batch_y})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(l) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Calculate accuracy for MNIST test images\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
        "                                      Y: mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= 810.3694, Training Accuracy= 0.188\n",
            "Step 50, Minibatch Loss= 36.6873, Training Accuracy= 0.906\n",
            "Step 100, Minibatch Loss= 76.7652, Training Accuracy= 0.812\n",
            "Step 150, Minibatch Loss= 32.2930, Training Accuracy= 0.938\n",
            "Step 200, Minibatch Loss= 34.3492, Training Accuracy= 0.906\n",
            "Step 250, Minibatch Loss= 30.2908, Training Accuracy= 0.844\n",
            "Step 300, Minibatch Loss= 23.0249, Training Accuracy= 0.906\n",
            "Step 350, Minibatch Loss= 30.5035, Training Accuracy= 0.906\n",
            "Step 400, Minibatch Loss= 35.8833, Training Accuracy= 0.906\n",
            "Step 450, Minibatch Loss= 20.7671, Training Accuracy= 0.969\n",
            "Step 500, Minibatch Loss= 15.0355, Training Accuracy= 0.938\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.8978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-kg9u1e3s7N",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard\n",
        "With TensorBoard you can easily monitor the learning process. Unfortunately in Google Colab you cannot directly use TensorBoard, first you have to tunnel it to become  remotely accessible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6SdLQpX3wJu",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "By running the following commands you can tunnel TensorBoard to the outside world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdJm9TXGdkL",
        "colab_type": "code",
        "outputId": "200a95ef-f9d7-4abe-9e6b-b72aa748c4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 08:58:31--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.200.123.104, 52.203.66.95, 52.22.145.207, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.200.123.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.28M  14.3MB/s    in 1.0s    \n",
            "\n",
            "2019-04-07 08:58:32 (14.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u2ZTaQEjwZL",
        "colab_type": "text"
      },
      "source": [
        "The following will give you an url. By opening it you can access your remote TensorBoard.\n",
        "\n",
        "Modify *LOG_DIR* if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdjKlI7KGn60",
        "colab_type": "code",
        "outputId": "c31deea0-e548-40ec-dc28-73da9d07702f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LOG_DIR = './log_test'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6007 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://2427574d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tH6AdNoHB2L",
        "colab_type": "text"
      },
      "source": [
        "### Visualization\n",
        "You can also visualize the computational graph by using TensorBoard. First you have to save the graph to a summary file:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LC7ni4Xd9IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = tf.summary.FileWriter('./log_test')\n",
        "writer.add_graph(tf.get_default_graph())\n",
        "writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-VN1y76ckKR",
        "colab_type": "text"
      },
      "source": [
        "Now open the above link and select Graph in the drop-down menu in the top right corner. It will show your computational graph.\n",
        "\n",
        "If you are running this notebook on your own machine, you can just use the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8GZu0EYHGXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard --logdir ./log_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XgTd_-j3wZ6",
        "colab_type": "text"
      },
      "source": [
        "## High-level API\n",
        "Keras is also available as a high-level API for TensorFlow. You can use it by importing the **[tf.keras](https://www.tensorflow.org/guide/keras)** module, but be aware that it might not be the latest Keras version available from PyPi.\n",
        "\n",
        "Before you move on runtime reset may be necessary because of the visualization. You can do it at: **Runtime -> Reset all runtimes...**. (Warning: You will lose all data from your virtual machine.) After that do not run any previous block except the [remote setup](#scrollTo=9cdJm9TXGdkL)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18QEHTywHVUN",
        "colab_type": "text"
      },
      "source": [
        "#### TensorBoard Callback\n",
        "Using **[tf.keras.callbacks.TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)** we can easily log information during training, that can be later visualized using TensorBoard. It allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model.\n",
        "\n",
        "**Main arguments:**\n",
        "\n",
        "*  **log_dir:** the path of the directory where to save the log files to be parsed by TensorBoard.\n",
        "* **histogram_freq:** frequency (in epochs) at which to compute activation and weight histograms for the layers of the model. If set to 0, histograms won't be computed. Validation data (or split) must be specified for histogram visualizations.\n",
        "* **batch_size:** size of batch of inputs to feed to the network for histograms computation.\n",
        "* **write_graph:** whether to visualize the graph in TensorBoard. The log file can become quite large when write_graph is set to True.\n",
        "* **write_grads:** whether to visualize gradient histograms in TensorBoard.  histogram_freq must be greater than 0.\n",
        "* **write_images:** whether to write model weights to visualize as image in TensorBoard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ0v5nPL32eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir='./log_keras', \n",
        "                         histogram_freq=1,\n",
        "                         batch_size=batch_size,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVc6CqOIHcUJ",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization\n",
        "With TensorBoard you can see details about the network during and after training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkPjAFFBjZ07",
        "colab_type": "code",
        "outputId": "ee2728e0-6407-4484-92ee-2ec03082e995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LOG_DIR = './log_keras'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6007 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://953864d8.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNTyY-MQHW4V",
        "colab_type": "text"
      },
      "source": [
        "#### Build an MLP\n",
        "But for now we have nothing to see, so let's build and train a simple neural network. During trainingTensorBoard will automatically update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUFGSBJeHb4r",
        "colab_type": "code",
        "outputId": "c9b144a8-47f4-4309-a863-4ff01f8ab0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=batch_size, \n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 17s 277us/sample - loss: 0.2968 - acc: 0.9129 - val_loss: 0.1430 - val_acc: 0.9577\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 15s 249us/sample - loss: 0.1423 - acc: 0.9577 - val_loss: 0.1050 - val_acc: 0.9672\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 17s 282us/sample - loss: 0.1062 - acc: 0.9678 - val_loss: 0.0848 - val_acc: 0.9744\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 15s 255us/sample - loss: 0.0880 - acc: 0.9726 - val_loss: 0.0750 - val_acc: 0.9764\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 16s 269us/sample - loss: 0.0745 - acc: 0.9761 - val_loss: 0.0766 - val_acc: 0.9766\n",
            "10000/10000 [==============================] - 0s 44us/sample - loss: 0.0766 - acc: 0.9766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07656257087504491, 0.9766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KbKX_Gu32re",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "* Low-level introduction: https://www.tensorflow.org/guide/low_level_intro\n",
        "* Tutorials: https://www.tensorflow.org/tutorials/\n",
        "* Examples: https://github.com/aymericdamien/TensorFlow-Examples\n",
        "* TensorBoard in Google Colab: https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n"
      ]
    }
  ]
}